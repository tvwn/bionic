{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import sys\n",
    "from pylab import rcParams\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Read the CSV files into DataFrame objects\n",
    "energyData = pd.read_csv(r'C:\\Users\\torst\\anaconda3\\O4\\Datat\\Energy and weather datasets\\energy_dataset.csv')\n",
    "weatherData = pd.read_csv(r'C:\\Users\\torst\\anaconda3\\O4\\Datat\\Energy and weather datasets\\weather_features.csv')\n",
    "\n",
    "# Set indexes and handle columns\n",
    "energyData.set_index('time', inplace=True)\n",
    "weatherData.set_index('dt_iso', inplace=True)\n",
    "energyData.columns = energyData.columns.map(lambda x: x + '_MWh' if x != 'price day ahead' and x != 'price actual' else x)\n",
    "columns = energyData.columns[energyData.columns.str.contains('price day ahead|price actual')]\n",
    "energyData.rename(columns=dict(zip(columns, columns + '_€/Mwh')), inplace=True)\n",
    "\n",
    "# Drop irrelevant columns and interpolate missing values\n",
    "energyData = energyData.drop(['generation hydro pumped storage aggregated_MWh',\n",
    "                              'forecast wind offshore eday ahead_MWh'], axis=1)\n",
    "energyData.interpolate(method='linear', inplace=True, axis=0)\n",
    "energyData = energyData.drop(['generation fossil coal-derived gas_MWh',\n",
    "                              'generation fossil oil shale_MWh', 'generation fossil peat_MWh',\n",
    "                              'generation geothermal_MWh', 'generation marine_MWh',\n",
    "                              'generation wind offshore_MWh'], axis=1)\n",
    "\n",
    "# Handle weather data and location information\n",
    "weatherData = weatherData.reset_index().drop_duplicates(subset=['dt_iso', 'city_name']).set_index('dt_iso')\n",
    "weatherData = weatherData.reset_index()\n",
    "weatherData = weatherData.rename(columns={'dt_iso': 'time'})\n",
    "cities = weatherData['city_name'].unique().tolist()\n",
    "geolocator = Nominatim(user_agent=\"Energy_Data_Location_ANN\")\n",
    "\n",
    "# Function to get latitude and longitude using geopy\n",
    "def geo_locator(city, country):\n",
    "    loc = geolocator.geocode(str(city + ',' + country))\n",
    "    return loc.latitude, loc.longitude\n",
    "\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for city in cities:\n",
    "    location = geo_locator(city, 'Spain')\n",
    "    latitudes.append(location[0])\n",
    "    longitudes.append(location[1])\n",
    "\n",
    "weatherData['Latitude'] = 0\n",
    "weatherData['Longitude'] = 0\n",
    "\n",
    "# Assign latitude and longitude values based on city\n",
    "weatherData['Latitude'].loc[weatherData['city_name'] == 'Valencia'] = latitudes[0]\n",
    "weatherData['Latitude'].loc[weatherData['city_name'] == 'Madrid'] = latitudes[1]\n",
    "weatherData['Latitude'].loc[weatherData['city_name'] == 'Bilbao'] = latitudes[2]\n",
    "weatherData['Latitude'].loc[weatherData['city_name'] == ' Barcelona'] = latitudes[3]\n",
    "weatherData['Latitude'].loc[weatherData['city_name'] == 'Seville'] = latitudes[4]\n",
    "\n",
    "weatherData['Longitude'].loc[weatherData['city_name'] == 'Valencia'] = longitudes[0]\n",
    "weatherData['Longitude'].loc[weatherData['city_name'] == 'Madrid'] = longitudes[1]\n",
    "weatherData['Longitude'].loc[weatherData['city_name'] == 'Bilbao'] = longitudes[2]\n",
    "weatherData['Longitude'].loc[weatherData['city_name'] == ' Barcelona'] = longitudes[3]\n",
    "weatherData['Longitude'].loc[weatherData['city_name'] == 'Seville'] = longitudes[4]\n",
    "\n",
    "# Encode weather-related categorical features\n",
    "weatherData['weather_main'] = label_encoder.fit_transform(weatherData['weather_main'])\n",
    "weatherData['weather_description'] = label_encoder.fit_transform(weatherData['weather_description'])\n",
    "weatherData['weather_icon'] = label_encoder.fit_transform(weatherData['weather_icon'])\n",
    "\n",
    "if len(energyData) != (len(weatherData) / 5):\n",
    "    print('Length not 5 times more')\n",
    "\n",
    "# Split weather data by cities\n",
    "weatherData1, weatherData2, weatherData3, weatherData4, weatherData5 = [y for _, y in weatherData.groupby('city_name')]\n",
    "\n",
    "# Function to add city suffix to feature names\n",
    "def add_city(dataframe):\n",
    "    city_name = dataframe.iloc[0]['city_name']\n",
    "    dataframe = dataframe.set_index(['time'])\n",
    "    dataframe = dataframe.drop(['city_name'], axis=1)\n",
    "    dataframe = dataframe.add_suffix(city_name)\n",
    "    return dataframe\n",
    "\n",
    "weatherData_list = [weatherData1, weatherData2, weatherData3, weatherData4, weatherData5]\n",
    "weatherData_result = []\n",
    "\n",
    "# Apply the 'add_city' function to all weather dataframes\n",
    "for data in weatherData_list:\n",
    "    weatherData_result.append(add_city(data))\n",
    "\n",
    "# Reset index of energy data for merging\n",
    "energyData = energyData.reset_index()\n",
    "\n",
    "# Reset index of weather dataframes for merging\n",
    "for i in range(len(weatherData_result)):\n",
    "    weatherData_result[i] = weatherData_result[i].reset_index()\n",
    "\n",
    "# Merge weather dataframes and energy data based on time\n",
    "completeDataset = reduce(lambda x, y: pd.merge(x, y, on='time'),\n",
    "                         [energyData, weatherData_result[0], weatherData_result[1], weatherData_result[2],\n",
    "                          weatherData_result[3], weatherData_result[4]])\n",
    "\n",
    "# Preprocess time-related features\n",
    "completeDataset['time'] = completeDataset['time'].str[:-9]\n",
    "completeDataset['time'] = completeDataset['time'].apply(lambda x: pd.to_datetime(str(x), format='%Y-%m-%d %H:%M'))\n",
    "completeDataset['time'] = completeDataset['time'].dt.strftime('%d-%m-%Y %H:%M')\n",
    "completeDataset['time'] = completeDataset['time'].apply(lambda x: pd.to_datetime(str(x), format='%d-%m-%Y %H:%M'))\n",
    "\n",
    "# Extract date and time components\n",
    "completeDataset['month'] = completeDataset['time'].dt.month\n",
    "completeDataset['day'] = completeDataset['time'].dt.day\n",
    "completeDataset['Hour_Minute'] = completeDataset['time'].dt.time\n",
    "completeDataset['Week_Day'] = completeDataset['time'].dt.weekday\n",
    "\n",
    "# Set time as index\n",
    "completeDataset = completeDataset.set_index('time', drop=True)\n",
    "\n",
    "# Define energy and weather-related metrics\n",
    "energy_metrics = ['total load actual_MWh', 'price actual_€/Mwh']\n",
    "weather_metrics = completeDataset.loc[:, 'temp Barcelona':'LongitudeValencia']\n",
    "weather_metrics = weather_metrics.drop(['LatitudeBilbao', 'LongitudeBilbao', 'LatitudeValencia',\n",
    "                                        'LongitudeValencia', 'LatitudeMadrid', 'LongitudeMadrid',\n",
    "                                        'Latitude Barcelona', 'Longitude Barcelona', 'LatitudeSeville',\n",
    "                                        'LongitudeSeville'], axis=1)\n",
    "\n",
    "# Merge energy and weather metrics\n",
    "cont = pd.merge(completeDataset[energy_metrics], weather_metrics, left_index=True, right_index=True)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "calculation = cont.corr()\n",
    "\n",
    "# Display correlation matrices\n",
    "print('Energy matrix \\n', calculation['total load actual_MWh'])\n",
    "print('Price matrix \\n', calculation['price actual_€/Mwh'])\n",
    "\n",
    "# Set city weights\n",
    "Bilbao_weight = 1\n",
    "Seville_weight = 2\n",
    "Valencia_weight = 3\n",
    "Barcelona_weight = 4\n",
    "Madrid_weight = 5\n",
    "\n",
    "# Apply city weights\n",
    "completeDataset['Bilbao_weight'] = Bilbao_weight\n",
    "completeDataset['Seville_weight'] = Seville_weight\n",
    "completeDataset['Valencia_weight'] = Valencia_weight\n",
    "completeDataset['Barcelona_weight'] = Barcelona_weight\n",
    "completeDataset['Madrid_weight'] = Madrid_weight\n",
    "\n",
    "# Calculate fossil and renewable generation\n",
    "completeDataset['coal_oil_fossil_MWh'] = completeDataset['generation fossil brown coal/lignite_MWh'] + completeDataset['generation fossil gas_MWh'] + completeDataset['generation fossil hard coal_MWh'] + completeDataset['generation fossil oil_MWh']\n",
    "completeDataset['renewables_MWh'] = completeDataset['generation hydro pumped storage consumption_MWh'] + completeDataset['generation hydro run-of-river and poundage_MWh'] + completeDataset['generation hydro water reservoir_MWh'] + completeDataset['generation other renewable_MWh'] + completeDataset['generation solar_MWh'] + completeDataset['generation wind onshore_MWh']\n",
    "\n",
    "# Shift renewable and fossil generation data\n",
    "tempFossil = completeDataset['coal_oil_fossil_MWh']\n",
    "tempRenewables = completeDataset['renewables_MWh']\n",
    "tempBiomass = completeDataset['generation biomass_MWh']\n",
    "tempBiomass = tempBiomass.shift(periods=24, fill_value=0)\n",
    "tempFossil = tempFossil.shift(periods=24, fill_value=0)\n",
    "tempRenewables = tempRenewables.shift(periods=24, fill_value=0)\n",
    "completeDataset['coal_oil_fossil_MWh_24Hours'] = tempFossil\n",
    "completeDataset['renewables_MWh_24Hours'] = tempRenewables\n",
    "completeDataset['generation biomass_MWh_24Hours'] = tempBiomass\n",
    "\n",
    "# Set discrepancy threshold for weather features\n",
    "discrepancy_threshold = 0.05\n",
    "\n",
    "# Determine relevant weather features based on correlation\n",
    "weather_features = []\n",
    "for index, value in calculation['price actual_€/Mwh'].items():\n",
    "    if value > discrepancy_threshold:\n",
    "        weather_features.append(index)\n",
    "\n",
    "print('Relevant Features: \\n', weather_features)\n",
    "\n",
    "# Define relevant features for modeling\n",
    "relevant_features = ['day', 'month', 'Hour_Minute', 'Week_Day', 'total load forecast_MWh', 'total load actual_MWh',\n",
    "                     'price actual_€/Mwh', 'price day ahead_€/Mwh', 'LatitudeBilbao', 'LongitudeBilbao',\n",
    "                     'LatitudeValencia', 'LongitudeValencia', 'LatitudeMadrid', 'LongitudeMadrid',\n",
    "                     'Latitude Barcelona', 'Longitude Barcelona', 'LatitudeSeville', 'LongitudeSeville',\n",
    "                     'temp Barcelona', 'temp_min Barcelona', 'temp_max Barcelona',\n",
    "                     'weather_description Barcelona', 'tempBilbao', 'temp_minBilbao', 'temp_maxBilbao',\n",
    "                     'pressureBilbao', 'weather_idBilbao', 'tempMadrid', 'temp_minMadrid', 'temp_maxMadrid',\n",
    "                     'temp_minSeville', 'pressureSeville', 'weather_idSeville', 'tempValencia', 'temp_minValencia',\n",
    "                     'coal_oil_fossil_MWh_24Hours', 'renewables_MWh_24Hours', 'generation biomass_MWh_24Hours',\n",
    "                     'forecast solar day ahead_MWh', 'forecast wind onshore day ahead_MWh']\n",
    "\n",
    "# Filter completeDataset based on relevant features\n",
    "completeDataset = completeDataset[relevant_features]\n",
    "\n",
    "# Drop latitude and longitude columns\n",
    "completeDataset = completeDataset.drop(['LatitudeBilbao', 'LongitudeBilbao', 'LatitudeValencia', 'LongitudeValencia',\n",
    "                                        'LatitudeMadrid', 'LongitudeMadrid', 'Latitude Barcelona',\n",
    "                                        'Longitude Barcelona', 'LatitudeSeville', 'LongitudeSeville',\n",
    "                                        'total load actual_MWh'], axis=1)\n",
    "\n",
    "# Drop initial 24 rows with shifted data\n",
    "completeDataset = completeDataset[24:]\n",
    "\n",
    "# Split features and labels\n",
    "features = completeDataset.drop(['price actual_€/Mwh'], axis=1)\n",
    "label = completeDataset['price actual_€/Mwh']\n",
    "\n",
    "# Encode time-related features\n",
    "features['Hour_Minute'] = label_encoder.fit_transform(features['Hour_Minute'])\n",
    "features['month'] = label_encoder.fit_transform(features['month'])\n",
    "features['day'] = label_encoder.fit_transform(features['day'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, shuffle=True, test_size=0.3)\n",
    "\n",
    "# Separate price day ahead for plotting\n",
    "price_day_ahed_test = X_test['price day ahead_€/Mwh']\n",
    "\n",
    "# Drop price day ahead for training\n",
    "X_test.drop(['price day ahead_€/Mwh'], axis=1, inplace=True)\n",
    "X_train.drop(['price day ahead_€/Mwh'], axis=1, inplace=True)\n",
    "\n",
    "# Initialize LightGBM model\n",
    "model = lgb.LGBMRegressor(objective='regression')\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict prices on the test data\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error and R2 score for predictions\n",
    "mse_train = mean_squared_error(y_train, y_train_predict)\n",
    "mse_val = mean_squared_error(y_test, y_test_predict)\n",
    "r2_val = r2_score(y_test, y_test_predict)\n",
    "\n",
    "print('Mean Square Error on Train Set:', mse_train)\n",
    "print('Mean Square Error on Test Set:', mse_val)\n",
    "print('R2 Score on Test Set:', r2_val)\n",
    "\n",
    "# Calculate cross-validation scores\n",
    "def validation_cv(parameter_tuning):\n",
    "    folds = KFold(numberFolds, shuffle=True).get_n_splits(X_train.values)\n",
    "    score = -cross_val_score(model, X_train.values, y_train, scoring='neg_mean_squared_error', cv=folds)\n",
    "    return score\n",
    "\n",
    "scores = validation_cv(model)\n",
    "score_mean = scores.mean()\n",
    "\n",
    "print(f\"Mean CV Score: {score_mean:.2f}, {parameter_tuning}\")\n",
    "for i in range(len(scores)):\n",
    "    print(f\"CV fold {i} => Score = {scores[i]:.2}\")\n",
    "\n",
    "# Plot actual vs. predicted values using Seaborn regplot\n",
    "Expected_actual_price = y_test\n",
    "Predicted_actual_price = model.predict(X_test)\n",
    "Predicted_actual_price = pd.DataFrame(data=Predicted_actual_price, columns=['predicted price actual_€/Mwh'])\n",
    "plot_data = Expected_actual_price.reset_index()\n",
    "plot_data['predicted price actual_€/Mwh'] = Predicted_actual_price\n",
    "plot_data.drop('time', inplace=True, axis=1)\n",
    "\n",
    "sn.regplot(x=\"price actual_€/Mwh\", y=\"predicted price actual_€/Mwh\", data=plot_data, fit_reg=True)\n",
    "plt.title('Expected vs Predicted Values with LightGBM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "bf989e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_day_ahead_plot = price_day_ahed_test.reset_index()\n",
    "price_day_ahead_plot= price_day_ahead_plot.drop('time', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "dc4df487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better than TSO: 93.66 % of the time\n",
      "Predicted on average % from actual price:  4.45 % \n",
      "TSO on average % from actual price:  18.17 % \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price actual_€/Mwh</th>\n",
       "      <th>predicted price actual_€/Mwh</th>\n",
       "      <th>price day ahead_€/Mwh</th>\n",
       "      <th>Expected discrepancy</th>\n",
       "      <th>Predicted discrepancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.32</td>\n",
       "      <td>43.654205</td>\n",
       "      <td>36.35</td>\n",
       "      <td>5.97</td>\n",
       "      <td>1.334205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.22</td>\n",
       "      <td>64.702066</td>\n",
       "      <td>55.35</td>\n",
       "      <td>13.87</td>\n",
       "      <td>4.517934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.09</td>\n",
       "      <td>56.909839</td>\n",
       "      <td>51.17</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.180161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.56</td>\n",
       "      <td>56.142104</td>\n",
       "      <td>45.01</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.417896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.72</td>\n",
       "      <td>70.234246</td>\n",
       "      <td>59.89</td>\n",
       "      <td>13.83</td>\n",
       "      <td>3.485754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.92</td>\n",
       "      <td>69.996509</td>\n",
       "      <td>65.96</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.076509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.26</td>\n",
       "      <td>46.336528</td>\n",
       "      <td>39.00</td>\n",
       "      <td>5.26</td>\n",
       "      <td>2.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58.38</td>\n",
       "      <td>59.977445</td>\n",
       "      <td>54.54</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1.597445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51.84</td>\n",
       "      <td>57.607075</td>\n",
       "      <td>65.71</td>\n",
       "      <td>13.87</td>\n",
       "      <td>5.767075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68.77</td>\n",
       "      <td>70.885090</td>\n",
       "      <td>59.99</td>\n",
       "      <td>8.78</td>\n",
       "      <td>2.115090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54.90</td>\n",
       "      <td>56.266746</td>\n",
       "      <td>48.49</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.366746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>69.06</td>\n",
       "      <td>70.725003</td>\n",
       "      <td>64.00</td>\n",
       "      <td>5.06</td>\n",
       "      <td>1.665003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44.70</td>\n",
       "      <td>46.306087</td>\n",
       "      <td>39.19</td>\n",
       "      <td>5.51</td>\n",
       "      <td>1.606087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64.13</td>\n",
       "      <td>63.948860</td>\n",
       "      <td>55.74</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.181140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75.32</td>\n",
       "      <td>66.625877</td>\n",
       "      <td>63.03</td>\n",
       "      <td>12.29</td>\n",
       "      <td>8.694123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.52</td>\n",
       "      <td>20.025232</td>\n",
       "      <td>66.26</td>\n",
       "      <td>52.74</td>\n",
       "      <td>6.505232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>52.52</td>\n",
       "      <td>52.284152</td>\n",
       "      <td>47.76</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.235848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>39.72</td>\n",
       "      <td>42.127926</td>\n",
       "      <td>34.47</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.407926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22.62</td>\n",
       "      <td>19.829545</td>\n",
       "      <td>11.60</td>\n",
       "      <td>11.02</td>\n",
       "      <td>2.790455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51.20</td>\n",
       "      <td>50.493577</td>\n",
       "      <td>41.36</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.706423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price actual_€/Mwh  predicted price actual_€/Mwh  price day ahead_€/Mwh  \\\n",
       "0                42.32                     43.654205                  36.35   \n",
       "1                69.22                     64.702066                  55.35   \n",
       "2                57.09                     56.909839                  51.17   \n",
       "3                56.56                     56.142104                  45.01   \n",
       "4                73.72                     70.234246                  59.89   \n",
       "5                69.92                     69.996509                  65.96   \n",
       "6                44.26                     46.336528                  39.00   \n",
       "7                58.38                     59.977445                  54.54   \n",
       "8                51.84                     57.607075                  65.71   \n",
       "9                68.77                     70.885090                  59.99   \n",
       "10               54.90                     56.266746                  48.49   \n",
       "11               69.06                     70.725003                  64.00   \n",
       "12               44.70                     46.306087                  39.19   \n",
       "13               64.13                     63.948860                  55.74   \n",
       "14               75.32                     66.625877                  63.03   \n",
       "15               13.52                     20.025232                  66.26   \n",
       "16               52.52                     52.284152                  47.76   \n",
       "17               39.72                     42.127926                  34.47   \n",
       "18               22.62                     19.829545                  11.60   \n",
       "19               51.20                     50.493577                  41.36   \n",
       "\n",
       "    Expected discrepancy  Predicted discrepancy  \n",
       "0                   5.97               1.334205  \n",
       "1                  13.87               4.517934  \n",
       "2                   5.92               0.180161  \n",
       "3                  11.55               0.417896  \n",
       "4                  13.83               3.485754  \n",
       "5                   3.96               0.076509  \n",
       "6                   5.26               2.076528  \n",
       "7                   3.84               1.597445  \n",
       "8                  13.87               5.767075  \n",
       "9                   8.78               2.115090  \n",
       "10                  6.41               1.366746  \n",
       "11                  5.06               1.665003  \n",
       "12                  5.51               1.606087  \n",
       "13                  8.39               0.181140  \n",
       "14                 12.29               8.694123  \n",
       "15                 52.74               6.505232  \n",
       "16                  4.76               0.235848  \n",
       "17                  5.25               2.407926  \n",
       "18                 11.02               2.790455  \n",
       "19                  9.84               0.706423  "
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate discrepancies and perform analysis\n",
    "plotData['price day ahead_€/Mwh'] = price_day_ahead_plot\n",
    "\n",
    "# Calculate discrepancies between actual and forecasted prices\n",
    "plotData['Expected discrepancy'] = abs(plotData['price day ahead_€/Mwh'] - plotData['price actual_€/Mwh'])\n",
    "plotData['Predicted discrepancy'] = abs(plotData['price actual_€/Mwh'] - plotData['predicted price actual_€/Mwh'])\n",
    "\n",
    "# Calculate total number of data points\n",
    "total_datapoints = plotData.shape[0]\n",
    "\n",
    "# Calculate percentage of predictions better and worse than TSO forecast\n",
    "predictions_better_than_TSO = plotData[plotData['Expected discrepancy'] > plotData['Predicted discrepancy']].shape[0] / total_datapoints * 100\n",
    "predictions_worse_than_TSO = plotData[plotData['Expected discrepancy'] < plotData['Predicted discrepancy']].shape[0] / total_datapoints * 100\n",
    "\n",
    "# Calculate average prediction improvement over TSO\n",
    "average_better = plotData['Predicted discrepancy'].mean() / plotData['price actual_€/Mwh'].mean()\n",
    "average_better = average_better * 100\n",
    "\n",
    "# Calculate TSO's average improvement over actual price\n",
    "TSO_average_better = plotData['Expected discrepancy'].mean() / plotData['price actual_€/Mwh'].mean()\n",
    "TSO_average_better = TSO_average_better * 100\n",
    "\n",
    "# Print analysis results\n",
    "print(f\"Better than TSO: {predictions_better_than_TSO:4.2f} % of the time\")\n",
    "print(f\"Predicted on average % from actual price: {average_better:4.2f} %\")\n",
    "print(f\"TSO on average % from actual price: {TSO_average_better:4.2f} %\")\n",
    "\n",
    "# Display the first 20 rows of the data\n",
    "print(plotData.head(20))\n",
    "\n",
    "# Plotting of discrepancies (commented out)\n",
    "# plt.plot(plotData['Expected discrepancy'], 'r+')\n",
    "# plt.plot(plotData['Predicted discrepancy'], 'bo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e02e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  degree=   1, score_mean=-70.68,  PolynomialFeatures(degree=1, include_bias=False)\n",
      "      CV fold 0  =>  score = -6.9e+01\n",
      "      CV fold 1  =>  score = -7.5e+01\n",
      "      CV fold 2  =>  score = -7.1e+01\n",
      "      CV fold 3  =>  score = -6.9e+01\n",
      "      CV fold 4  =>  score = -6.6e+01\n",
      "      CV fold 5  =>  score = -7e+01\n",
      "      CV fold 6  =>  score = -7.7e+01\n",
      "      CV fold 7  =>  score = -6.9e+01\n",
      "      CV fold 8  =>  score = -7.4e+01\n",
      "      CV fold 9  =>  score = -6.8e+01\n",
      "  degree=   2, score_mean=-39.72,  PolynomialFeatures(include_bias=False)\n",
      "      CV fold 0  =>  score = -3.8e+01\n",
      "      CV fold 1  =>  score = -4e+01\n",
      "      CV fold 2  =>  score = -4e+01\n",
      "      CV fold 3  =>  score = -3.9e+01\n",
      "      CV fold 4  =>  score = -3.8e+01\n",
      "      CV fold 5  =>  score = -3.9e+01\n",
      "      CV fold 6  =>  score = -4.3e+01\n",
      "      CV fold 7  =>  score = -3.9e+01\n",
      "      CV fold 8  =>  score = -4.2e+01\n",
      "      CV fold 9  =>  score = -3.9e+01\n",
      "  degree=   3, score_mean=-32.94,  PolynomialFeatures(degree=3, include_bias=False)\n",
      "      CV fold 0  =>  score = -2.3e+01\n",
      "      CV fold 1  =>  score = -2.8e+01\n",
      "      CV fold 2  =>  score = -2.9e+01\n",
      "      CV fold 3  =>  score = -2.8e+01\n",
      "      CV fold 4  =>  score = -2.6e+01\n",
      "      CV fold 5  =>  score = -3.9e+01\n",
      "      CV fold 6  =>  score = -5.1e+01\n",
      "      CV fold 7  =>  score = -4.1e+01\n",
      "      CV fold 8  =>  score = -3.2e+01\n",
      "      CV fold 9  =>  score = -3.2e+01\n"
     ]
    }
   ],
   "source": [
    "# Polynomial regression with varying degrees\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "\n",
    "for i in range(len(degrees)):\n",
    "    # Create polynomial features up to the current degree\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    \n",
    "    # Linear regression model\n",
    "    linear_regression = LinearRegression()\n",
    "    \n",
    "    # Create a pipeline with polynomial features and linear regression\n",
    "    pipeline = Pipeline([\n",
    "        (\"polynomial_features\", polynomial_features),\n",
    "        (\"linear_regression\", linear_regression)\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    X_train_poly = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the models using cross-validation\n",
    "    scores = cross_val_score(X_train_poly, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    # Calculate the mean cross-validation score\n",
    "    score_mean = scores.mean()\n",
    "    \n",
    "    # Print the results for the current polynomial degree\n",
    "    print(f\"  degree={degrees[i]:4d}, score_mean={score_mean:4.2f},  {polynomial_features}\") \n",
    "    for i in range(len(scores)):\n",
    "        print(f\"      CV fold {i}  =>  score = {scores[i]:.2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fc5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "d6aeb392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch=   0, mse_train=70.59, mse_val=77.66\n",
      "  epoch=   1, mse_train=200.15, mse_val=205.75\n",
      "  epoch=   2, mse_train=70.60, mse_val=77.70\n",
      "  epoch=   3, mse_train=70.64, mse_val=77.64\n",
      "  epoch=   4, mse_train=70.62, mse_val=77.63\n",
      "  epoch=   5, mse_train=49.22, mse_val=56.00\n",
      "  epoch=   6, mse_train=61.37, mse_val=70.56\n"
     ]
    }
   ],
   "source": [
    "# Scale the features using MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "X_train_scaled = scale.fit_transform(X_train) \n",
    "X_test_scaled = scale.fit_transform(X_test)\n",
    "\n",
    "n_epochs = 7\n",
    "for epoch in range(n_epochs):\n",
    "    # Create an MLPRegressor model\n",
    "    mlp = MLPRegressor(\n",
    "        activation='tanh',    # Activation function\n",
    "        hidden_layer_sizes=epoch+1, # Number of hidden neurons in the layer\n",
    "        alpha=0.5,           # Regularization parameter (small value)\n",
    "        solver='lbfgs',       # Quasi-Newton solver\n",
    "        max_iter=99999999999999,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Fit the MLPRegressor model on scaled training data\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions on both training and test data\n",
    "    y_train_predict = mlp.predict(X_train_scaled)\n",
    "    y_test_predict = mlp.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate mean squared error for training and test predictions\n",
    "    mse_train = mean_squared_error(y_train, y_train_predict)\n",
    "    mse_val = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "    # Print the results for the current epoch\n",
    "    print(f\"  epoch={epoch:4d}, mse_train={mse_train:4.2f}, mse_val={mse_val:4.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
